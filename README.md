# LLMChat with WebGPU & Transformers.js

åŸºäº WebGPU å’Œ Transformers.js çš„æµè§ˆå™¨ç«¯å¤§è¯­è¨€æ¨¡å‹èŠå¤©å®ç°ï¼Œé€šè¿‡ GPU åŠ é€Ÿå®ç°é«˜æ•ˆçš„ AI å¯¹è¯ä½“éªŒã€‚

![webgpu llm chat](https://github.com/xinzhanguo/webgpullmchat/blob/main/webgpullmchat.png?raw=true)

## âœ¨ ç‰¹æ€§

- **WebGPU åŠ é€Ÿ** - åˆ©ç”¨æµè§ˆå™¨ GPU èµ„æºåŠ é€Ÿæ¨ç†
- **é›¶æœåŠ¡ç«¯ä¾èµ–** - å®Œå…¨åœ¨æµè§ˆå™¨ç«¯è¿è¡Œ
- **å³å¼€å³ç”¨** - æ— éœ€å¤æ‚ç¯å¢ƒé…ç½®
- **å®æ—¶äº¤äº’** - ä½å»¶è¿Ÿçš„æµå¼å“åº”
- **æ¨¡å‹å…¼å®¹** - æ”¯æŒ Hugging Face æ ¼å¼çš„ LLM æ¨¡å‹

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚
- æ”¯æŒ WebGPU çš„æµè§ˆå™¨ï¼ˆChrome 113+ / Edge 113+ï¼‰
- ç°ä»£ JavaScript è¿è¡Œç¯å¢ƒ

### æ‰“å¼€ä½“éªŒ
- æµè§ˆå™¨ä¸­æ‰“å¼€å³å¯ä½“éªŒ

### å¼€å‘è¯´æ˜

* @huggingface/transformers@3.0.0
* webgpu

```
import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.0';

// Create a text generation pipeline
const generator = await pipeline(
  "text-generation",
  "onnx-community/Qwen2.5-0.5B-Instruct",
  { dtype: "q4", device: "webgpu" },
);

// Define the list of messages
const messages = [
  { role: "system", content: "You are a helpful assistant." },
  { role: "user", content: "Tell me a funny joke." },
];

// Generate a response
const output = await generator(messages, { max_new_tokens: 128 });
console.log(output[0].generated_text.at(-1).content);

```